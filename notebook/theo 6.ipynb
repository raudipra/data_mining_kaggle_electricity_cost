{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_x = df.drop(['B'], axis=1)\n",
    "df_y = pd.DataFrame(data=df[['A', 'B']])\n",
    "df_y['B_'] = np.log(df_y['B'])\n",
    "\n",
    "combine = [df_x, test]\n",
    "\n",
    "d = {'A': list(range(144))}\n",
    "tenth_minute_of_the_day = pd.DataFrame(data=d)\n",
    "\n",
    "d = {'A': list(range(1008))}\n",
    "tenth_minute_of_the_week = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['tenth_minute_of_the_day'] = (dataset['A'] % 144)\n",
    "    dataset['tenth_minute_of_the_week'] = (dataset['A'] % (144*7))\n",
    "    \n",
    "def mean_energy_usage_per_time_unit_day(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].mean()\n",
    "        tenth_minute_of_the_day['mean'] = tenth_minute_of_the_day['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_mean\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def median_energy_usage_per_time_unit_day(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].median()\n",
    "        tenth_minute_of_the_day['median'] = tenth_minute_of_the_day['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_median\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def q1_energy_usage_per_time_unit_day(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].quantile(0.25)\n",
    "        tenth_minute_of_the_day['q1'] = tenth_minute_of_the_day['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_q1\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def q3_energy_usage_per_time_unit_day(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].quantile(0.75)\n",
    "        tenth_minute_of_the_day['q3'] = tenth_minute_of_the_day['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_q3\"] = dataset[time_unit].map(time_unit_dict)\n",
    "\n",
    "            ###########################################################\n",
    "            \n",
    "def mean_energy_usage_per_time_unit_week(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].mean()\n",
    "        tenth_minute_of_the_week['mean'] = tenth_minute_of_the_week['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_mean\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def median_energy_usage_per_time_unit_week(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].median()\n",
    "        tenth_minute_of_the_week['median'] = tenth_minute_of_the_week['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_median\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def q1_energy_usage_per_time_unit_week(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].quantile(0.25)\n",
    "        tenth_minute_of_the_week['q1'] = tenth_minute_of_the_week['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_q1\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "def q3_energy_usage_per_time_unit_week(time_unit):\n",
    "    time_unit_dict = {}\n",
    "    for _time_unit in df_x[time_unit].unique():\n",
    "        time_unit_dict[_time_unit] = df['B'].loc[df_x[time_unit].isin([_time_unit])].quantile(0.75)\n",
    "        tenth_minute_of_the_week['q3'] = tenth_minute_of_the_week['A'].map(time_unit_dict)\n",
    "        for dataset in combine:\n",
    "            dataset[time_unit + \"_energy_usage_q3\"] = dataset[time_unit].map(time_unit_dict)\n",
    "            \n",
    "mean_energy_usage_per_time_unit_day('tenth_minute_of_the_day')\n",
    "mean_energy_usage_per_time_unit_week('tenth_minute_of_the_week')\n",
    "\n",
    "median_energy_usage_per_time_unit_day('tenth_minute_of_the_day')\n",
    "median_energy_usage_per_time_unit_week('tenth_minute_of_the_week')\n",
    "\n",
    "q1_energy_usage_per_time_unit_day('tenth_minute_of_the_day')\n",
    "q1_energy_usage_per_time_unit_week('tenth_minute_of_the_week')\n",
    "\n",
    "q3_energy_usage_per_time_unit_day('tenth_minute_of_the_day')\n",
    "q3_energy_usage_per_time_unit_week('tenth_minute_of_the_week')\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['temp_diff'] = dataset[['D','F','H','J','L','P','R','T']].mean(axis=1) - dataset[['N', 'V']].mean(axis=1)\n",
    "    dataset['hum_diff'] = dataset[['E','G','I','K','M','Q','S','U']].mean(axis=1) - dataset[['O', 'X']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_wo_outlier_day_dict = {}\n",
    "min_wo_outlier_day_dict = {}\n",
    "\n",
    "for time_unit in df_x['tenth_minute_of_the_day'].unique():\n",
    "    data = df['B'].loc[df_x['tenth_minute_of_the_day'].isin([time_unit])]\n",
    "    m = 2\n",
    "    u = np.median(data)\n",
    "    s = np.std(data)\n",
    "    filtered = [e for e in data if (u - (m * s) < e < u + m * s)]\n",
    "    max_wo_outlier_day_dict[time_unit] = max(filtered)\n",
    "    min_wo_outlier_day_dict[time_unit] = min(filtered)\n",
    "    \n",
    "#     print(data)\n",
    "#     print(s)\n",
    "#     print(filtered)\n",
    "\n",
    "for time_unit in df_x['tenth_minute_of_the_day'].unique():\n",
    "    tenth_minute_of_the_day['max_wo_outlier'] = tenth_minute_of_the_day['A'].map(max_wo_outlier_day_dict)\n",
    "    tenth_minute_of_the_day['min_wo_outlier'] = tenth_minute_of_the_day['A'].map(min_wo_outlier_day_dict)\n",
    "    \n",
    "######################    \n",
    "    \n",
    "max_wo_outlier_week_dict = {}\n",
    "min_wo_outlier_week_dict = {}\n",
    "\n",
    "for time_unit in df_x['tenth_minute_of_the_week'].unique():\n",
    "    data = df['B'].loc[df_x['tenth_minute_of_the_week'].isin([time_unit])]\n",
    "    m = 2\n",
    "    u = np.median(data)\n",
    "    s = np.std(data)\n",
    "    filtered = [e for e in data if (u - (m * s) < e < u + m * s)]\n",
    "    max_wo_outlier_week_dict[time_unit] = max(filtered)\n",
    "    min_wo_outlier_week_dict[time_unit] = min(filtered)\n",
    "    \n",
    "#     print(data)\n",
    "#     print(s)\n",
    "#     print(filtered)\n",
    "\n",
    "for time_unit in df_x['tenth_minute_of_the_week'].unique():\n",
    "    tenth_minute_of_the_week['max_wo_outlier'] = tenth_minute_of_the_week['A'].map(max_wo_outlier_week_dict)\n",
    "    tenth_minute_of_the_week['min_wo_outlier'] = tenth_minute_of_the_week['A'].map(min_wo_outlier_week_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####HAPUS OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 7\n",
      "Estimated number of clusters: 32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "af1 = AffinityPropagation().fit(tenth_minute_of_the_day.drop(['A'], axis=1))\n",
    "cluster_centers_indices1 = af1.cluster_centers_indices_\n",
    "\n",
    "n_clusters_1 = len(cluster_centers_indices1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_1)\n",
    "\n",
    "day_class = pd.Series(af1.predict(tenth_minute_of_the_day.drop(['A'], axis=1)))\n",
    "\n",
    "tenth_minute_of_the_day['class'] = pd.Series(af1.predict(tenth_minute_of_the_day.drop(['A'], axis=1)))\n",
    "\n",
    "df_x['tenth_minute_of_the_day_class'] = df_x['tenth_minute_of_the_day'].map(day_class).astype('str')\n",
    "test['tenth_minute_of_the_day_class'] = test['tenth_minute_of_the_day'].map(day_class).astype('str')\n",
    "\n",
    "#############################\n",
    "\n",
    "af2 = AffinityPropagation().fit(tenth_minute_of_the_week.drop(['A'], axis=1))\n",
    "cluster_centers_indices2 = af2.cluster_centers_indices_\n",
    "\n",
    "n_clusters_2 = len(cluster_centers_indices2)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_2)\n",
    "\n",
    "week_class = pd.Series(af2.predict(tenth_minute_of_the_week.drop(['A'], axis=1)))\n",
    "\n",
    "tenth_minute_of_the_week['class'] = pd.Series(af1.predict(tenth_minute_of_the_week.drop(['A'], axis=1)))\n",
    "\n",
    "df_x['tenth_minute_of_the_week_class'] = df_x['tenth_minute_of_the_week'].map(week_class).astype('str')\n",
    "test['tenth_minute_of_the_week_class'] = test['tenth_minute_of_the_week'].map(week_class).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_data_day = {}\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    temp = {}\n",
    "    temp['data'] = df_x.loc[df_x['tenth_minute_of_the_day_class'] == str(time_class)]\n",
    "    temp['y'] = df_y.loc[df_x['tenth_minute_of_the_day_class'] == str(time_class)]\n",
    "    model_and_data_day[time_class] = temp\n",
    "    \n",
    "model_and_data_week = {}\n",
    "\n",
    "for time_class in week_class.unique():\n",
    "    temp = {}\n",
    "    temp['data'] = df_x.loc[df_x['tenth_minute_of_the_week_class'] == str(time_class)]\n",
    "    temp['y'] = df_y.loc[df_x['tenth_minute_of_the_week_class'] == str(time_class)]\n",
    "    model_and_data_week[time_class] = temp\n",
    "    \n",
    "test_model_and_data_day = {}\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    temp = {}\n",
    "    temp['data'] = test.loc[test['tenth_minute_of_the_day_class'] == str(time_class)]\n",
    "    test_model_and_data_day[time_class] = temp\n",
    "    \n",
    "test_model_and_data_week = {}\n",
    "\n",
    "for time_class in week_class.unique():\n",
    "    temp = {}\n",
    "    temp['data'] = test.loc[test['tenth_minute_of_the_week_class'] == str(time_class)]\n",
    "    test_model_and_data_week[time_class] = temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_x)\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    model_and_data_day[time_class]['data_scaled'] = scaler.transform(model_and_data_day[time_class]['data'])\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    model_and_data_week[time_class]['data_scaled'] = scaler.transform(model_and_data_week[time_class]['data'])\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    test_model_and_data_day[time_class]['data_scaled'] = scaler.transform(test_model_and_data_day[time_class]['data'])\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    test_model_and_data_week[time_class]['data_scaled'] = scaler.transform(test_model_and_data_week[time_class]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.20439764 24.26955591 20.64295508  4.62965971 20.32646118  3.26885314\n",
      " 16.29968439  4.92607155 17.45305607  2.47332374 15.69303417  2.03984215\n",
      "  9.87615338 11.75759651 13.48906803  4.893571   23.9585583  12.14655761\n",
      " 14.58107692  8.65523438  8.09759461  3.99503307 10.14766749  2.41666005\n",
      "  0.93960358  2.60330993  1.03189808  1.03189808  6.25784229  1.52110382\n",
      " 87.89654942 85.89522784 92.26775601 73.75653517 83.57374833 98.24675304\n",
      " 64.71148589 58.70458336  5.00485177 12.09772267  5.09633339  6.8834654 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 # all positive\n",
    "from sklearn.feature_selection import f_classif # can negative\n",
    "from sklearn.feature_selection import mutual_info_classif # can negative\n",
    "\n",
    "selector = SelectKBest(f_classif, k=20).fit(df_x_scaled, df_y['B_'])\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    model_and_data_day[time_class]['data_scaled_selected'] = selector.transform(model_and_data_day[time_class]['data_scaled'])\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    model_and_data_week[time_class]['data_scaled_selected'] = selector.transform(model_and_data_week[time_class]['data_scaled'])\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    test_model_and_data_day[time_class]['data_scaled_selected'] = selector.transform(test_model_and_data_day[time_class]['data_scaled'])\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    test_model_and_data_week[time_class]['data_scaled_selected'] = selector.transform(test_model_and_data_week[time_class]['data_scaled'])\n",
    "    \n",
    "scores = selector.scores_\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(model_and_data_day[time_class]['data_scaled_selected'], model_and_data_day[time_class]['y']['B_'], test_size=0.2, shuffle=False)\n",
    "    model_and_data_day[time_class]['x_train'] = x_train\n",
    "    model_and_data_day[time_class]['x_test'] = x_test\n",
    "    model_and_data_day[time_class]['y_train'] = y_train\n",
    "    model_and_data_day[time_class]['y_test'] = y_test\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    x_train, x_test, y_train, y_test = train_test_split(model_and_data_week[time_class]['data_scaled_selected'], model_and_data_week[time_class]['y']['B_'], test_size=0.2, shuffle=False)\n",
    "    model_and_data_week[time_class]['x_train'] = x_train\n",
    "    model_and_data_week[time_class]['x_test'] = x_test\n",
    "    model_and_data_week[time_class]['y_train'] = y_train\n",
    "    model_and_data_week[time_class]['y_test'] = y_test \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x_scaled_selected, df_y['B_'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\t121.13207374547692\n",
      "5\t171.41582047831236\n",
      "1\t80.99728586445003\n",
      "0\t130.28138052922048\n",
      "6\t101.61290323248195\n",
      "2\t57.77582553705093\n",
      "3\t32.60688797651208\n",
      "\n",
      "\n",
      "27\t(118,)\t110.54733495757577\n",
      "20\t(97,)\t86.36626746349508\n",
      "1\t(65,)\t108.06379403564836\n",
      "18\t(17,)\t314.2414690300621\n",
      "22\t(33,)\t194.0394719105054\n",
      "29\t(44,)\t171.17437677804597\n",
      "31\t(60,)\t130.8529974817851\n",
      "0\t(14,)\t150.7369552609659\n",
      "15\t(25,)\t184.06667103971682\n",
      "6\t(19,)\t199.29044384529965\n",
      "16\t(159,)\t77.29592869388222\n",
      "23\t(81,)\t67.21858794235942\n",
      "5\t(61,)\t133.610933766042\n",
      "24\t(71,)\t147.05164075912427\n",
      "11\t(25,)\t120.42366990246353\n",
      "25\t(174,)\t25.708748677786833\n",
      "26\t(189,)\t63.718105048614895\n",
      "8\t(171,)\t17.514609743600293\n",
      "7\t(406,)\t52.30657040240089\n",
      "17\t(497,)\t18.165942623105973\n",
      "10\t(22,)\t144.72738149814757\n",
      "13\t(67,)\t95.13629769752265\n",
      "14\t(45,)\t196.8828544844091\n",
      "12\t(89,)\t54.06077570102497\n",
      "9\t(76,)\t94.7610136530654\n",
      "2\t(53,)\t141.6346457108502\n",
      "28\t(9,)\t302.83836925297976\n",
      "21\t(22,)\t159.61455847056425\n",
      "3\t(17,)\t195.90743395845976\n",
      "4\t(11,)\t155.571899134833\n",
      "30\t(22,)\t206.4786408381624\n",
      "19\t(17,)\t135.18933508226084\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for time_class in day_class.unique():\n",
    "    model_and_data_day[time_class]['clf'] = svm.SVR(C=1, gamma=0.01, kernel='rbf')\n",
    "    model_and_data_day[time_class]['clf'].fit(model_and_data_day[time_class]['x_train'], model_and_data_day[time_class]['y_train'])\n",
    "    model_and_data_day[time_class]['prediction'] = model_and_data_day[time_class]['clf'].predict(model_and_data_day[time_class]['x_test'])\n",
    "    print (str(time_class) + \"\\t\" + str(math.sqrt(mean_squared_error(model_and_data_day[time_class]['y_test'].apply(np.exp), np.apply_along_axis(np.exp, 0, model_and_data_day[time_class]['prediction'])))))\n",
    "#     count = 0\n",
    "#     for a in model_and_data_day[time_class]['y_test'].apply(np.exp):\n",
    "#         print (str(a) + \" \\tpredicted: \" + str(np.apply_along_axis(np.exp, 0, prediction)[count]))\n",
    "#         count = count + 1\n",
    "    \n",
    "print()\n",
    "print()\n",
    "\n",
    "for time_class in week_class.unique():\n",
    "    model_and_data_week[time_class]['clf'] = svm.SVR(C=1, gamma=0.01, kernel='rbf')\n",
    "    model_and_data_week[time_class]['clf'].fit(model_and_data_week[time_class]['x_train'], model_and_data_week[time_class]['y_train'])\n",
    "    model_and_data_week[time_class]['prediction'] = model_and_data_week[time_class]['clf'].predict(model_and_data_week[time_class]['x_test'])\n",
    "    print (str(time_class) + \"\\t\" + str(model_and_data_week[time_class]['y_test'].shape) + \"\\t\" + str(math.sqrt(mean_squared_error(model_and_data_week[time_class]['y_test'].apply(np.exp), np.apply_along_axis(np.exp, 0,  model_and_data_week[time_class]['prediction'])))))\n",
    "#     count = 0\n",
    "#     for a in model_and_data_week[time_class]['y_test'].apply(np.exp):\n",
    "#         print (str(a) + \" \\tpredicted: \" + str(np.apply_along_axis(np.exp, 0, prediction)[count]))\n",
    "#         count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_class in day_class.unique():\n",
    "    test_model_and_data_day[time_class]['prediction'] = np.apply_along_axis(np.exp, 0,  model_and_data_day[time_class]['clf'].predict(test_model_and_data_day[time_class]['data_scaled_selected']))\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    test_model_and_data_week[time_class]['prediction'] = np.apply_along_axis(np.exp, 0,  model_and_data_week[time_class]['clf'].predict(test_model_and_data_week[time_class]['data_scaled_selected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 20)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_and_data_week[20]['data_scaled_selected'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    207.000000\n",
       "mean      72.729792\n",
       "std       13.347076\n",
       "min       47.477010\n",
       "25%       63.413770\n",
       "50%       70.436261\n",
       "75%       81.682410\n",
       "max      121.680667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test_model_and_data_week[20]['prediction']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# for time_class in week_class.unique():\n",
    "#     test.loc[test['tenth_minute_of_the_week_class'] == str(time_class), 'prediction'] = pd.Series(test_model_and_data_week[time_class]['prediction'])\n",
    "    \n",
    "for time_class in week_class.unique():\n",
    "    c = 0\n",
    "    for index, row in test.loc[test['tenth_minute_of_the_week_class'] == str(time_class), 'prediction'].iteritems():\n",
    "        test.set_value(index, 'prediction', pd.Series(test_model_and_data_week[time_class]['prediction'])[c])\n",
    "        c = c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>AA</th>\n",
       "      <th>AB</th>\n",
       "      <th>AC</th>\n",
       "      <th>tenth_minute_of_the_day</th>\n",
       "      <th>tenth_minute_of_the_week</th>\n",
       "      <th>tenth_minute_of_the_day_energy_usage_mean</th>\n",
       "      <th>tenth_minute_of_the_week_energy_usage_mean</th>\n",
       "      <th>tenth_minute_of_the_day_energy_usage_median</th>\n",
       "      <th>tenth_minute_of_the_week_energy_usage_median</th>\n",
       "      <th>tenth_minute_of_the_day_energy_usage_q1</th>\n",
       "      <th>tenth_minute_of_the_week_energy_usage_q1</th>\n",
       "      <th>tenth_minute_of_the_day_energy_usage_q3</th>\n",
       "      <th>tenth_minute_of_the_week_energy_usage_q3</th>\n",
       "      <th>temp_diff</th>\n",
       "      <th>hum_diff</th>\n",
       "      <th>tenth_minute_of_the_day_class</th>\n",
       "      <th>tenth_minute_of_the_week_class</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13815</td>\n",
       "      <td>0</td>\n",
       "      <td>22.426667</td>\n",
       "      <td>45.463333</td>\n",
       "      <td>21.533333</td>\n",
       "      <td>43.590000</td>\n",
       "      <td>25.390000</td>\n",
       "      <td>40.466667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>20.89</td>\n",
       "      <td>47.00</td>\n",
       "      <td>10.363333</td>\n",
       "      <td>15.733333</td>\n",
       "      <td>21.39</td>\n",
       "      <td>32.834000</td>\n",
       "      <td>23.790000</td>\n",
       "      <td>41.430000</td>\n",
       "      <td>21.1</td>\n",
       "      <td>44.260000</td>\n",
       "      <td>10.566667</td>\n",
       "      <td>747.566667</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>46.580781</td>\n",
       "      <td>46.580781</td>\n",
       "      <td>135</td>\n",
       "      <td>711</td>\n",
       "      <td>106.421053</td>\n",
       "      <td>84.615385</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>-0.116167</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>85.376474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13816</td>\n",
       "      <td>0</td>\n",
       "      <td>22.390000</td>\n",
       "      <td>45.133333</td>\n",
       "      <td>21.463333</td>\n",
       "      <td>43.663333</td>\n",
       "      <td>25.323333</td>\n",
       "      <td>40.326667</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>38.792857</td>\n",
       "      <td>20.89</td>\n",
       "      <td>47.03</td>\n",
       "      <td>9.363333</td>\n",
       "      <td>27.733333</td>\n",
       "      <td>21.39</td>\n",
       "      <td>32.790000</td>\n",
       "      <td>23.856667</td>\n",
       "      <td>41.156667</td>\n",
       "      <td>21.1</td>\n",
       "      <td>44.245000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>747.550000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.853704</td>\n",
       "      <td>26.853704</td>\n",
       "      <td>136</td>\n",
       "      <td>712</td>\n",
       "      <td>114.526316</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>-6.224435</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>85.692333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13817</td>\n",
       "      <td>0</td>\n",
       "      <td>22.390000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>21.390000</td>\n",
       "      <td>43.723333</td>\n",
       "      <td>25.290000</td>\n",
       "      <td>40.060000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>38.678000</td>\n",
       "      <td>20.89</td>\n",
       "      <td>47.03</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>40.296667</td>\n",
       "      <td>21.39</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>23.790000</td>\n",
       "      <td>40.633333</td>\n",
       "      <td>21.1</td>\n",
       "      <td>44.133333</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>747.533333</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>5.133333</td>\n",
       "      <td>24.624531</td>\n",
       "      <td>24.624531</td>\n",
       "      <td>137</td>\n",
       "      <td>713</td>\n",
       "      <td>119.578947</td>\n",
       "      <td>156.153846</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>-12.628583</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>91.136398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13818</td>\n",
       "      <td>0</td>\n",
       "      <td>22.390000</td>\n",
       "      <td>45.433333</td>\n",
       "      <td>21.290000</td>\n",
       "      <td>43.966667</td>\n",
       "      <td>25.230000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.968571</td>\n",
       "      <td>38.590000</td>\n",
       "      <td>20.89</td>\n",
       "      <td>47.00</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>44.630000</td>\n",
       "      <td>21.39</td>\n",
       "      <td>32.985000</td>\n",
       "      <td>23.790000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>21.1</td>\n",
       "      <td>43.933333</td>\n",
       "      <td>10.966667</td>\n",
       "      <td>747.516667</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>31.556785</td>\n",
       "      <td>31.556785</td>\n",
       "      <td>138</td>\n",
       "      <td>714</td>\n",
       "      <td>114.736842</td>\n",
       "      <td>149.230769</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.472738</td>\n",
       "      <td>-14.763958</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>166.630410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13819</td>\n",
       "      <td>0</td>\n",
       "      <td>22.390000</td>\n",
       "      <td>45.360000</td>\n",
       "      <td>21.290000</td>\n",
       "      <td>43.826667</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>39.966667</td>\n",
       "      <td>21.956000</td>\n",
       "      <td>38.590000</td>\n",
       "      <td>20.89</td>\n",
       "      <td>47.00</td>\n",
       "      <td>9.026667</td>\n",
       "      <td>47.866667</td>\n",
       "      <td>21.39</td>\n",
       "      <td>33.204286</td>\n",
       "      <td>23.790000</td>\n",
       "      <td>40.590000</td>\n",
       "      <td>21.1</td>\n",
       "      <td>43.760000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>747.500000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.060258</td>\n",
       "      <td>44.060258</td>\n",
       "      <td>139</td>\n",
       "      <td>715</td>\n",
       "      <td>106.421053</td>\n",
       "      <td>131.538462</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>12.187417</td>\n",
       "      <td>-16.396131</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>97.052502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A  C          D          E          F          G          H          I  \\\n",
       "0  13815  0  22.426667  45.463333  21.533333  43.590000  25.390000  40.466667   \n",
       "1  13816  0  22.390000  45.133333  21.463333  43.663333  25.323333  40.326667   \n",
       "2  13817  0  22.390000  45.000000  21.390000  43.723333  25.290000  40.060000   \n",
       "3  13818  0  22.390000  45.433333  21.290000  43.966667  25.230000  40.000000   \n",
       "4  13819  0  22.390000  45.360000  21.290000  43.826667  25.200000  39.966667   \n",
       "\n",
       "           J          K      L      M          N          O      P          Q  \\\n",
       "0  22.000000  38.960000  20.89  47.00  10.363333  15.733333  21.39  32.834000   \n",
       "1  22.000000  38.792857  20.89  47.03   9.363333  27.733333  21.39  32.790000   \n",
       "2  22.000000  38.678000  20.89  47.03   8.660000  40.296667  21.39  32.900000   \n",
       "3  21.968571  38.590000  20.89  47.00   8.600000  44.630000  21.39  32.985000   \n",
       "4  21.956000  38.590000  20.89  47.00   9.026667  47.866667  21.39  33.204286   \n",
       "\n",
       "           R          S     T          U          V           W     X  \\\n",
       "0  23.790000  41.430000  21.1  44.260000  10.566667  747.566667  68.0   \n",
       "1  23.856667  41.156667  21.1  44.245000  10.700000  747.550000  68.0   \n",
       "2  23.790000  40.633333  21.1  44.133333  10.833333  747.533333  68.0   \n",
       "3  23.790000  40.500000  21.1  43.933333  10.966667  747.516667  68.0   \n",
       "4  23.790000  40.590000  21.1  43.760000  11.100000  747.500000  68.0   \n",
       "\n",
       "          Y          Z        AA         AB         AC  \\\n",
       "0  4.333333  31.333333  4.866667  46.580781  46.580781   \n",
       "1  4.500000  33.500000  5.000000  26.853704  26.853704   \n",
       "2  4.666667  35.666667  5.133333  24.624531  24.624531   \n",
       "3  4.833333  37.833333  5.266667  31.556785  31.556785   \n",
       "4  5.000000  40.000000  5.400000  44.060258  44.060258   \n",
       "\n",
       "   tenth_minute_of_the_day  tenth_minute_of_the_week  \\\n",
       "0                      135                       711   \n",
       "1                      136                       712   \n",
       "2                      137                       713   \n",
       "3                      138                       714   \n",
       "4                      139                       715   \n",
       "\n",
       "   tenth_minute_of_the_day_energy_usage_mean  \\\n",
       "0                                 106.421053   \n",
       "1                                 114.526316   \n",
       "2                                 119.578947   \n",
       "3                                 114.736842   \n",
       "4                                 106.421053   \n",
       "\n",
       "   tenth_minute_of_the_week_energy_usage_mean  \\\n",
       "0                                   84.615385   \n",
       "1                                  130.000000   \n",
       "2                                  156.153846   \n",
       "3                                  149.230769   \n",
       "4                                  131.538462   \n",
       "\n",
       "   tenth_minute_of_the_day_energy_usage_median  \\\n",
       "0                                         70.0   \n",
       "1                                         80.0   \n",
       "2                                         80.0   \n",
       "3                                         80.0   \n",
       "4                                         80.0   \n",
       "\n",
       "   tenth_minute_of_the_week_energy_usage_median  \\\n",
       "0                                          80.0   \n",
       "1                                          80.0   \n",
       "2                                          80.0   \n",
       "3                                          80.0   \n",
       "4                                          80.0   \n",
       "\n",
       "   tenth_minute_of_the_day_energy_usage_q1  \\\n",
       "0                                     50.0   \n",
       "1                                     50.0   \n",
       "2                                     50.0   \n",
       "3                                     50.0   \n",
       "4                                     50.0   \n",
       "\n",
       "   tenth_minute_of_the_week_energy_usage_q1  \\\n",
       "0                                      70.0   \n",
       "1                                      70.0   \n",
       "2                                      60.0   \n",
       "3                                      60.0   \n",
       "4                                      60.0   \n",
       "\n",
       "   tenth_minute_of_the_day_energy_usage_q3  \\\n",
       "0                                    100.0   \n",
       "1                                    110.0   \n",
       "2                                    110.0   \n",
       "3                                    110.0   \n",
       "4                                    105.0   \n",
       "\n",
       "   tenth_minute_of_the_week_energy_usage_q3  temp_diff   hum_diff  \\\n",
       "0                                      80.0  11.850000  -0.116167   \n",
       "1                                     120.0  12.270000  -6.224435   \n",
       "2                                     160.0  12.533333 -12.628583   \n",
       "3                                     250.0  12.472738 -14.763958   \n",
       "4                                     110.0  12.187417 -16.396131   \n",
       "\n",
       "  tenth_minute_of_the_day_class tenth_minute_of_the_week_class  prediction  \n",
       "0                             6                             25   85.376474  \n",
       "1                             4                              9   85.692333  \n",
       "2                             4                              5   91.136398  \n",
       "3                             4                             31  166.630410  \n",
       "4                             6                              9   97.052502  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['A', 'prediction']].to_csv(\"submission t2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
